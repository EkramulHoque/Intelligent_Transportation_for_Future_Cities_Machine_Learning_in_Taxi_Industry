    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std
0        129.256471        0.015708      129.256435       0.142606
1        128.251362        0.185388      128.251154       0.268218
2        127.300111        0.199442      127.299487       0.243058
3        126.237666        0.331184      126.236873       0.327870
4        125.397213        0.338461      125.396439       0.331174
5        124.345190        0.409416      124.344582       0.395119
6        123.406802        0.545497      123.406128       0.529665
7        122.381950        0.507402      122.381387       0.482282
8        121.461758        0.537497      121.461110       0.498954
9        120.624065        0.590913      120.623710       0.571650
10       119.795347        0.599335      119.794785       0.565620
11       118.852697        0.724051      118.852168       0.703391
12       118.056231        0.769870      118.055605       0.738589
13       117.180192        0.916665      117.179290       0.872704
14       116.371314        0.894893      116.370574       0.848405
15       115.416493        0.937642      115.415556       0.902442
16       114.514702        1.021232      114.513814       0.987294
17       113.703813        0.985461      113.702646       0.939657
18       112.954698        1.001904      112.953472       0.960429
19       112.079102        1.066295      112.077939       1.031695
20       111.311729        1.115284      111.310707       1.079417
21       110.409286        1.025770      110.408297       0.986982
22       109.510972        0.895293      109.509871       0.853608
23       108.749600        0.887019      108.748914       0.849096
24       107.961602        0.902616      107.960851       0.858788
25       107.215324        0.892207      107.214518       0.836720
26       106.440534        0.848703      106.439777       0.803013
27       105.729539        0.900623      105.728831       0.855727
28       104.972880        0.828840      104.972189       0.786862
29       104.133392        0.788949      104.132976       0.772426
30       103.332923        0.936873      103.332406       0.923974
31       102.570087        1.064163      102.569458       1.040649
32       101.848065        1.095449      101.847413       1.069921
33       101.128591        1.038347      101.128257       1.027387
34       100.385523        1.080810      100.385561       1.087920
35        99.717632        1.028681       99.717905       1.036916
36        98.979854        1.108225       98.979977       1.111803
37        98.331984        1.175570       98.332425       1.179228
38        97.700303        1.191628       97.700772       1.199112
39        97.014400        1.071188       97.015033       1.079568
40        96.357607        1.102392       96.358186       1.101940
41        95.621177        1.177662       95.621839       1.181506
42        94.921542        1.205452       94.922215       1.209980
43        94.311771        1.212153       94.312801       1.217163
44        93.748959        1.217327       93.749711       1.221719
45        93.158309        1.247136       93.158913       1.247836
46        92.498831        1.344708       92.499392       1.339561
47        91.908467        1.390167       91.908935       1.386089
48        91.235124        1.359165       91.235721       1.360911
49        90.672471        1.361671       90.673095       1.366902

dropped = ['VendorID','RatecodeID','mta_tax','tolls_amount','improvement_surcharge',
		'total_amount','payment_type','trip_type','dispatch','PickUp_hr']
k-fold= 10
learning rate = 0.01